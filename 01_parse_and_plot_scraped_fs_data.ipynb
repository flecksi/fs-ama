{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running this notebook, results from the scrapy spider must be available (in the fscrawl directory)\n",
    "### In order to run the crawler, use the following command (in the fscrawl directory):\n",
    "```bash\n",
    "scrapy crawl fs_episodes -O fs-episodes.json -a dlwebvtt=true\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import pathlib\n",
    "from datetime import datetime, date\n",
    "\n",
    "fscrawl_path = pathlib.Path(\"fscrawl\")\n",
    "\n",
    "plot_output_path = pathlib.Path(\"plots\")\n",
    "plot_output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "write_parquet_files = False\n",
    "if write_parquet_files:\n",
    "    processed_output_path = pathlib.Path(\"processed_dataframes\")\n",
    "    processed_output_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to parse VTT Trancsiption Files\n",
    "### combining some of the entries for later use with LLMs and RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine rows (from top to bottom) until the text length is greater than 500\n",
    "def combine_rows(df: pd.DataFrame, max_len: int = 500) -> pd.DataFrame:\n",
    "    combined_rows = []\n",
    "    current_text = \"\"\n",
    "    start = df.iloc[0][\"start\"]\n",
    "    end = df.iloc[0][\"end\"]\n",
    "    voices = [df.iloc[0][\"voice\"]]\n",
    "    for i, row in df.iterrows():\n",
    "        if len(current_text) + row[\"text_len\"] > max_len:\n",
    "            duration = end - start\n",
    "            current_text = current_text.strip()\n",
    "            combined_rows.append(\n",
    "                dict(\n",
    "                    text=current_text,\n",
    "                    text_len=len(current_text),\n",
    "                    start=start,\n",
    "                    end=end,\n",
    "                    duration=duration.total_seconds(),\n",
    "                    voices=list(set(voices)),\n",
    "                )\n",
    "            )\n",
    "            current_text = row[\"text\"]\n",
    "            start = row[\"start\"]\n",
    "            voices = [row[\"voice\"]]\n",
    "        else:\n",
    "            current_text += \"\\n\" + row[\"text\"]\n",
    "            voices.append(row[\"voice\"])\n",
    "            end = row[\"end\"]\n",
    "    combined_rows.append(\n",
    "        dict(\n",
    "            text=current_text,\n",
    "            text_len=len(current_text),\n",
    "            start=start,\n",
    "            end=end,\n",
    "            duration=duration.total_seconds(),\n",
    "            voices=list(set(voices)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(combined_rows)\n",
    "    df[\"n_voices\"] = [len(x) for x in df[\"voices\"]]\n",
    "    return df\n",
    "\n",
    "# main parsing function\n",
    "def parse_vtt(\n",
    "    vttfile: pathlib.Path,\n",
    "    rec_date: date = None,\n",
    "    max_len: int = 500,\n",
    "    combine: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    with open(vttfile) as f:\n",
    "        alldata = f.read().strip()\n",
    "        block_strings = alldata.split(\"\\n\\n\")\n",
    "\n",
    "    if len(block_strings) <= 2:\n",
    "        return None\n",
    "\n",
    "    blocks = []\n",
    "    for block in block_strings[2:]:\n",
    "        lines = block.split(\"\\n\")\n",
    "        # if len(lines) <= 2:\n",
    "        #    return None\n",
    "        start, end = lines[0].split(\" --> \")\n",
    "\n",
    "        start_time = datetime.strptime(\n",
    "            start, \"%H:%M:%S.%f\"\n",
    "        )  # + timedelta(hours=20) #.time()\n",
    "        end_time = datetime.strptime(\n",
    "            end, \"%H:%M:%S.%f\"\n",
    "        )  # + timedelta(hours=20)#.time()\n",
    "        if isinstance(rec_date, date):\n",
    "            start_time = datetime.combine(rec_date, start_time.time())\n",
    "            end_time = datetime.combine(rec_date, end_time.time())\n",
    "        duration = end_time - start_time\n",
    "        voice, text = lines[1].split(\">\")\n",
    "        voice = voice.lstrip(\"<v \")\n",
    "        blocks.append(\n",
    "            dict(\n",
    "                start=start_time,\n",
    "                end=end_time,\n",
    "                duration=duration.total_seconds(),\n",
    "                voice=voice,\n",
    "                text=text,\n",
    "                text_len=len(text),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if combine:\n",
    "        return combine_rows(df=pd.DataFrame(blocks), max_len=max_len)\n",
    "    else:\n",
    "        return pd.DataFrame(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Combined VTT Rows based on text-length (used for embedding - to get a usable context per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vtt_combined = parse_vtt(\n",
    "    vttfile=fscrawl_path / \"episode_transcripts/FS136.vtt\",\n",
    "    rec_date=date(year=2014, month=7, day=8),\n",
    ")\n",
    "df_vtt_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Not combined - original VTT contents\n",
    "Sum up the talking durations per speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vtt = parse_vtt(\n",
    "    vttfile=fscrawl_path / \"episode_transcripts/FS136.vtt\",\n",
    "    rec_date=date(year=2014, month=7, day=8),\n",
    "    combine=False,\n",
    ")\n",
    "df_vtt.groupby(\"voice\").agg({\"duration\": \"sum\"}).sort_values(\n",
    "    by=\"duration\", ascending=False\n",
    ")# .sum().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse all available VTT files (combined) and store them in parquet format\n",
    "For later use in LLM RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_parquet_files:\n",
    "    vtt_dataframes = []\n",
    "    for vtt_file in list((fscrawl_path/\"episode_transcripts\").glob(\"*.vtt\")):\n",
    "        df_vvt = parse_vtt(vtt_file, max_len=500)\n",
    "        if df_vvt is not None:\n",
    "            vtt_dataframes.append(df_vvt)\n",
    "            df_vvt.to_parquet(processed_output_path / f\"df_vtt_{vtt_file.stem}_combined.parquet\")\n",
    "        else:\n",
    "            print(f\"Parsing {vtt_file}: Could not parse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse crawled episode metadata and combine&check VTT data\n",
    "- See the printed output for found issues with the VTT transcription files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fs = pd.read_json(fscrawl_path / \"fs-episodes.json\")\n",
    "\n",
    "df_fs[\"year\"] = df_fs[\"date\"].dt.year\n",
    "df_fs[\"month\"] = df_fs[\"date\"].dt.month_name()\n",
    "\n",
    "# convert guest column to boolean\n",
    "for col in df_fs.columns:\n",
    "    if col.startswith(\"guest:\"):\n",
    "        df_fs[col] = df_fs[col].fillna(False)\n",
    "        df_fs[col] = df_fs[col].astype(bool)\n",
    "\n",
    "# sort by date\n",
    "df_fs = df_fs.sort_values(by=\"date\")\n",
    "# reset index\n",
    "df_fs = df_fs.reset_index(drop=True)\n",
    "df_fs[\"episode_number\"] = df_fs.index + 1\n",
    "\n",
    "fs_records = []\n",
    "\n",
    "for i, row in df_fs.iterrows():\n",
    "    row_record_dict = row.to_dict()\n",
    "\n",
    "    duration_minutes_total = float(row.duration_minutes)\n",
    "    vtt_parsing_issue = False\n",
    "    vtt_speaker_mismatch = False\n",
    "    vtt_duration_mismatch = False\n",
    "    if row.webvtt_available:\n",
    "        vtt_filename = (\n",
    "            fscrawl_path / f\"episode_transcripts/{row.title.split(' ')[0]}.vtt\"\n",
    "        )\n",
    "        if vtt_filename.exists():\n",
    "            df_vtt = parse_vtt(vttfile=vtt_filename, combine=False)\n",
    "            if df_vtt is not None:\n",
    "                df_vtt_speaker_durations = (\n",
    "                    df_vtt.groupby(\"voice\")\n",
    "                    .agg({\"duration\": \"sum\"})\n",
    "                    .sort_values(by=\"duration\", ascending=False)\n",
    "                )\n",
    "                vtt_sum_of_speaker_durations_minutes = (\n",
    "                    df_vtt_speaker_durations.sum().values[0] / 60\n",
    "                )\n",
    "                speaker_duration_delta_minutes = (\n",
    "                    vtt_sum_of_speaker_durations_minutes - duration_minutes_total\n",
    "                )\n",
    "                row_record_dict.update(\n",
    "                    {\n",
    "                        \"vtt_sum_of_speaker_durations_minutes\": vtt_sum_of_speaker_durations_minutes,\n",
    "                    }\n",
    "                )\n",
    "                if speaker_duration_delta_minutes > 15:\n",
    "                    vtt_duration_mismatch = True\n",
    "                    print(\n",
    "                        f\"! {row.title}: {vtt_filename} - total duration mismatch: VTT is {speaker_duration_delta_minutes:.1f}min longer than description: {vtt_sum_of_speaker_durations_minutes:.1f} > {duration_minutes_total:.1f}\"\n",
    "                    )\n",
    "                elif speaker_duration_delta_minutes < -15:\n",
    "                    vtt_duration_mismatch = True\n",
    "                    print(\n",
    "                        f\"! {row.title}: {vtt_filename} - total duration mismatch: VTT is {-speaker_duration_delta_minutes:.1f}min shorter than description: {vtt_sum_of_speaker_durations_minutes:.1f} < {duration_minutes_total:.1f}\"\n",
    "                    )\n",
    "                speaker_set_from_description = set(row.guests)\n",
    "                speaker_set_from_vtt = set(df_vtt_speaker_durations.index)\n",
    "\n",
    "                if speaker_set_from_description != speaker_set_from_vtt:\n",
    "                    vtt_speaker_mismatch = True\n",
    "                    print(\n",
    "                        f\"! {row.title}: {vtt_filename} - speaker mismatch between VTT content and description: {sorted(speaker_set_from_vtt)} != {sorted(speaker_set_from_description)}\"\n",
    "                    )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"! {row.title}: {vtt_filename} could not be parsed (the VTT file might be empty)!\"\n",
    "                )\n",
    "                vtt_parsing_issue = True\n",
    "        else:\n",
    "            print(\n",
    "                f\"! {row.title}: {vtt_filename} does not exist (but it should - maybe the crawl-chache was deleted?)!\"\n",
    "            )\n",
    "            vtt_parsing_issue = True\n",
    "\n",
    "    row_record_dict.update(\n",
    "        {\n",
    "            \"vtt_parsing_issue\": vtt_parsing_issue,\n",
    "            \"vtt_speaker_mismatch\": vtt_speaker_mismatch,\n",
    "            \"vtt_duration_mismatch\": vtt_duration_mismatch,\n",
    "        }\n",
    "    )\n",
    "    fs_records.append(row_record_dict)\n",
    "\n",
    "df_fs = pd.DataFrame.from_records(fs_records)\n",
    "if write_parquet_files:\n",
    "    df_fs.to_parquet(processed_output_path / \"df_fs_episodes.parquet\")\n",
    "display(df_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for visualizations\n",
    "  - create a dataframe where each row is a single speaking part of one guest in one episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_records = []\n",
    "\n",
    "for i, row in df_fs.iterrows():\n",
    "    if row.webvtt_available:\n",
    "        vtt_filename = (\n",
    "            fscrawl_path / f\"episode_transcripts/{row.title.split(' ')[0]}.vtt\"\n",
    "        )\n",
    "        if vtt_filename.exists():\n",
    "            df_vtt = parse_vtt(vttfile=vtt_filename, combine=False)\n",
    "            if df_vtt is not None:\n",
    "                df_vtt_speaker_durations = (\n",
    "                    df_vtt.groupby(\"voice\")\n",
    "                    .agg({\"duration\": \"sum\"})\n",
    "                    .sort_values(by=\"duration\", ascending=False)\n",
    "                )\n",
    "                if not any([row.vtt_speaker_mismatch, row.vtt_duration_mismatch]):\n",
    "                    for speaker, duration in df_vtt_speaker_durations.iterrows():\n",
    "                        episode_dict = {\n",
    "                            \"episode_number\": row.episode_number,\n",
    "                            \"episode_title\": row.title,\n",
    "                            \"year\": row.year,\n",
    "                            \"month\": row.month,\n",
    "                            \"date\": row.date,\n",
    "                            \"duration_minutes\": duration[\"duration\"] / 60,\n",
    "                            \"speaker\": speaker,\n",
    "                            \"vtt_available\": row.webvtt_available,\n",
    "                            \"vtt_parsing_issue\": row.vtt_parsing_issue,\n",
    "                            \"vtt_speaker_mismatch\": row.vtt_speaker_mismatch,\n",
    "                            \"vtt_duration_mismatch\": row.vtt_duration_mismatch,\n",
    "                        }\n",
    "                        duration_records.append(episode_dict)\n",
    "                    continue\n",
    "\n",
    "    duration_minutes_total = float(row.duration_minutes)\n",
    "    guests = row.guests\n",
    "    duration_per_guest = duration_minutes_total / len(guests)\n",
    "    for guest in guests:\n",
    "        episode_dict = {\n",
    "            \"episode_number\": row.episode_number,\n",
    "            \"episode_title\": row.title,\n",
    "            \"year\": row.year,\n",
    "            \"month\": row.month,\n",
    "            \"date\": row.date,\n",
    "            \"duration_minutes\": duration_per_guest,\n",
    "            \"speaker\": guest,\n",
    "            \"vtt_available\": row.webvtt_available,\n",
    "            \"vtt_parsing_issue\": row.vtt_parsing_issue,\n",
    "            \"vtt_speaker_mismatch\": row.vtt_speaker_mismatch,\n",
    "            \"vtt_duration_mismatch\": row.vtt_duration_mismatch,\n",
    "        }\n",
    "        duration_records.append(episode_dict)\n",
    "\n",
    "df_speakers_and_durations = pd.DataFrame.from_records(duration_records)\n",
    "df_speakers_and_durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots from here on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot_fcn, plot_label in [\n",
    "    (px.sunburst, \"sunburst\"),\n",
    "    (px.treemap, \"treemap\"),\n",
    "    (px.icicle, \"icicle\"),\n",
    "]:\n",
    "\n",
    "    fig = plot_fcn(\n",
    "        df_speakers_and_durations,\n",
    "        path=[px.Constant(\"All Years\"), \"year\", \"month\", \"episode_title\", \"speaker\"],\n",
    "        values=\"duration_minutes\",\n",
    "        title=\"FREAKSHOW | Speaker durations in minutes | Year > Month > Episode > Speaker\",\n",
    "        # maxdepth=3,\n",
    "    )\n",
    "    # fig.show()\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=5, r=5, t=50, b=5),\n",
    "    )\n",
    "    fig.write_html(\n",
    "        plot_output_path/f\"{plot_label}_speaker_durations_year>month>episode>speaker.html\",\n",
    "        include_plotlyjs=\"cdn\",\n",
    "    )\n",
    "\n",
    "    fig = plot_fcn(\n",
    "        df_speakers_and_durations,\n",
    "        path=[px.Constant(\"All Guests\"), \"speaker\", \"year\", \"month\", \"episode_title\"],\n",
    "        values=\"duration_minutes\",\n",
    "        title=\"FREAKSHOW | Speaker durations in minutes| Speaker > Year > Month > Episode\",\n",
    "        # hovertemplate=\"<b>%{label}</b><br>%{value} minutes\",\n",
    "        # color=\"episode_title\"\n",
    "        # maxdepth=2,\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=5, r=5, t=50, b=5),\n",
    "    )\n",
    "    # fig.show()\n",
    "    fig.write_html(\n",
    "        plot_output_path\n",
    "        / f\"{plot_label}_speaker_durations_speaker>year>month>episode.html\",\n",
    "        include_plotlyjs=\"cdn\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    df_speakers_and_durations,\n",
    "    x=\"episode_number\",\n",
    "    # x=\"episode_title\",\n",
    "    y=\"duration_minutes\",\n",
    "    color=\"speaker\",\n",
    "    hover_data=[\"episode_title\", \"date\", \"vtt_available\", \"vtt_parsing_issue\", \"vtt_speaker_mismatch\", \"vtt_duration_mismatch\"],\n",
    ")\n",
    "# sort legend by duration\n",
    "# fig.for_each_trace(lambda t: t.update(name=t.name.split(\"=\")[1]))\n",
    "fig.update_layout(\n",
    "    title=\"FREAKSHOW | Speaker durations in minutes | Over Episodes\",\n",
    "    xaxis_title=\"Episode number\",\n",
    "    yaxis_title=\"Duration in minutes\",\n",
    "    legend_title=\"Guests<br>(in order of appearance)\",\n",
    ")\n",
    "fig.write_html(plot_output_path/\"bar_speaker_durations_over_episodes.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumsum = df_speakers_and_durations.pivot_table(\n",
    "    index=\"speaker\", \n",
    "    columns=\"date\", \n",
    "    values=\"duration_minutes\", aggfunc=\"sum\",\n",
    ").T.cumsum(axis=0)\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame=df_cumsum,\n",
    "    markers=True,\n",
    ").update_traces(connectgaps=True)\n",
    "fig.update_layout(\n",
    "    title=\"FREAKSHOW | Cumulative speaker durations in minutes | Over Time\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cumulative duration in minutes\",\n",
    "    legend_title=\"Guests\",\n",
    ")\n",
    "fig.write_html(plot_output_path/\"line_cumsum_speaker_durations_over_time.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make year colummn categorical\n",
    "df_fs[\"year\"] = df_fs[\"year\"].astype(str)\n",
    "\n",
    "fig = px.scatter(\n",
    "    data_frame=df_fs,\n",
    "    x=\"n_guests\",\n",
    "    y=\"duration_minutes\",\n",
    "    color=\"year\",\n",
    "    marginal_x=\"violin\",#\"rug\",#\"violin\",#\"histogram\",\n",
    "    marginal_y=\"violin\",#\"rug\",#\"violin\",#\"histogram\",\n",
    "    hover_data=[\"title\", \"date\"],\n",
    "    #facet_col=\"year\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"FREAKSHOW | Duration in minutes vs. Number of guests\",\n",
    "    xaxis_title=\"Number of guests\",\n",
    "    yaxis_title=\"Duration in minutes\",\n",
    "    legend_title=\"Year\",\n",
    ")\n",
    "fig.write_html(plot_output_path/\"scatter_duration_vs_n_guests.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    data_frame=df_fs,\n",
    "    x=\"date\",\n",
    "    y=\"duration_minutes\",\n",
    "    color=\"webvtt_available\",\n",
    "    color_discrete_map={True: \"green\", False: \"red\"},\n",
    "    size=\"n_guests\",\n",
    "    hover_data=[\"title\", \"guests\", \"vtt_parsing_issue\", \"vtt_duration_mismatch\", \"vtt_speaker_mismatch\"],\n",
    "    symbol=\"vtt_parsing_issue\",\n",
    "    symbol_sequence=[\"circle\", \"x\"],\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"FREAKSHOW | Episode Duration and Number of Guests | Over Time\",\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Duration in minutes\",\n",
    "    #legend_title=\"Transcript available\",\n",
    ")\n",
    "fig.write_html(plot_output_path/\"scatter_duration_vs_date.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## needs more thinking about...\n",
    "# fig = px.parallel_categories(\n",
    "#     data_frame=df_speakers_and_durations,\n",
    "#     #color=\"speaker\",\n",
    "#     dimensions=['year',\"speaker\"],\n",
    "#     #dimensions=[\"episode_number\",],\n",
    "#     #labels={\"episode_number\": \"Episode number\", \"duration_minutes\": \"Duration in minutes\", \"speaker\": \"Speaker\"},\n",
    "#     #color_continuous_scale=px.colors.sequential.Viridis,\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     title=\"FREAKSHOW | Speaker durations in minutes | Over Episodes\",\n",
    "#     xaxis_title=\"Episode number\",\n",
    "#     yaxis_title=\"Duration in minutes\",\n",
    "# )\n",
    "# fig.write_html(plot_output_path/\"parallel_coordinates_speaker_durations_over_episodes.html\", include_plotlyjs=\"cdn\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I dont like it any more...\n",
    "\n",
    "# fig = px.density_heatmap(\n",
    "#     data_frame=df_speakers_and_durations,\n",
    "#     x=\"year\",\n",
    "#     y=\"speaker\",\n",
    "#     z=\"duration_minutes\",\n",
    "#     color_continuous_scale=\"reds\",\n",
    "\n",
    "#     #marginal_x=\"rug\",\n",
    "#     #marginal_y=\"violin\",\n",
    "#     #color_continuous_scale=\"Viridis\",\n",
    "#     title=\"FREAKSHOW | Speaker durations in minutes | Over Years\",\n",
    "# )\n",
    "# fig.write_html(plot_output_path/\"density_heatmap_speaker_durations_over_years.html\", include_plotlyjs=\"cdn\")  \n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(\n",
    "    data_frame=df_fs,\n",
    "    x=\"year\",\n",
    "    y=\"month\",\n",
    "    z=\"duration_minutes\",\n",
    "    color_continuous_scale=\"reds\",\n",
    "    )\n",
    "# sort y-axis by month\n",
    "fig.update_layout(\n",
    "    title = \"FREAKSHOW | Total talking durations in minutes | Over Years and Months\",\n",
    ")\n",
    "fig.update_yaxes(categoryorder=\"array\", categoryarray=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"])\n",
    "fig.write_html(plot_output_path/\"density_heatmap_episode_durations_over_years_and_months.html\", include_plotlyjs=\"cdn\")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsama-pAdkqC_b-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
